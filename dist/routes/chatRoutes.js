import dotenv from "dotenv";
import express from "express";
import { v4 as uuidv4 } from "uuid";
import { graph } from "../supervisor";
import { HumanMessage } from "@langchain/core/messages";
import fetch from "node-fetch";
import { OpenAI, toFile } from "openai";
import twilio from "twilio";
import { initializeApp } from "firebase/app";
import { getDownloadURL, getStorage, ref, uploadBytesResumable, } from "firebase/storage";
import { ElevenLabsClient } from "elevenlabs";
import path from "path";
import axios from "axios";
import ffmpeg from "fluent-ffmpeg";
import fs from "fs";
import { fileURLToPath } from "url";
import { saveChatHistory, saveTemplateChatHistory, } from "../utils/saveHistoryDb";
import { getAvailableChatOn } from "../utils/getAvailableChatOn";
import { getAvailableForAudio } from "../utils/getAvailableForAudio";
const router = express.Router();
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
dotenv.config();
const MessagingResponse = twilio.twiml.MessagingResponse; // mandar un texto simple
const accountSid = process.env.TWILIO_ACCOUNT_SID;
const authToken = process.env.TWILIO_AUTH_TOKEN;
const client = twilio(accountSid, authToken); // mandar un texto con media
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});
// ElevenLabs Client
const elevenlabsClient = new ElevenLabsClient({
    apiKey: process.env.ELEVENLABS_API_KEY,
});
const firebaseConfig = {
    apiKey: process.env.FIREBASE_API_KEY,
    authDomain: process.env.FIREBASE_AUTH_DOMAIN,
    projectId: process.env.FIREBASE_PROJECT_ID,
    storageBucket: process.env.FIREBASE_STORAGE_BUCKET,
    messagingSenderId: process.env.FIREBASE_MESSAGING_SENDER_ID,
    appId: process.env.FIREBASE_APP_ID,
};
const app = initializeApp(firebaseConfig);
const storage = getStorage();
const createAudioStreamFromText = async (text) => {
    const audioStream = await elevenlabsClient.generate({
        voice: "Andrea",
        model_id: "eleven_flash_v2_5",
        text,
    });
    const chunks = [];
    for await (const chunk of audioStream) {
        chunks.push(chunk);
    }
    const content = Buffer.concat(chunks);
    return content;
};
let exportedFromNumber;
let globalConfig = {
    configurable: {
        thread_id: "",
        phone_number: "",
    },
};
// Endpoint para procesar mensajes
router.post("/induequipos/receive-message", async (req, res) => {
    const twiml = new MessagingResponse();
    const from = req.body.From;
    const to = req.body.To;
    // Parseo de numeros de telefono
    const fromColonIndex = from.indexOf(":");
    const toColonIndex = to.indexOf(":");
    // Numero de telefono que pasa de "whatsapp:+57XXXXXXXXX" a "+57XXXXXXXXX"
    const fromNumber = from.slice(fromColonIndex + 1); // N√∫mero del cliente
    const toNumber = to.slice(toColonIndex + 1);
    // fromNumber sin indicativo de pa√≠s
    const fromNumberWithoutCountryCode = fromNumber.slice(3); // N√∫mero del cliente sin indicativo de pa√≠s
    exportedFromNumber = fromNumber;
    globalConfig = {
        configurable: {
            thread_id: fromNumber,
            phone_number: fromNumber,
        },
    };
    try {
        let incomingMessage;
        let incomingImage;
        let firebaseImageUrl = "";
        console.log("Incoming message Type:", req.body.Body);
        if (req.body.MediaContentType0 &&
            req.body.MediaContentType0.includes("audio")) {
            try {
                const mediaUrl = await req.body.MediaUrl0;
                const response = await fetch(mediaUrl, {
                    headers: {
                        Authorization: `Basic ${Buffer.from(`${accountSid}:${authToken}`).toString("base64")}`,
                    },
                });
                const file = await toFile(response.body, "recording.wav");
                const transcription = await openai.audio.transcriptions.create({
                    file,
                    model: "whisper-1",
                    prompt: "Por favor, transcribe el audio y aseg√∫rate de escribir los n√∫meros exactamente como se pronuncian, sin espacios, comas, ni puntos. Por ejemplo, un n√∫mero de documento   debe ser transcrito como 123456789.",
                });
                const { text } = transcription;
                incomingMessage = text;
            }
            catch (error) {
                console.error("Error transcribing audio:", error);
                twiml.message("En este momento no puedo transcribir audios, por favor intenta con un mensaje de texto. O prueba grabando el audio nuevamente.");
                res.writeHead(200, { "Content-Type": "text/xml" });
                res.end(twiml.toString());
            }
        }
        else if (req.body.MessageType === "image") {
            const mediaUrl = await req.body.MediaUrl0;
            const response = await fetch(mediaUrl, {
                headers: {
                    Authorization: `Basic ${Buffer.from(`${accountSid}:${authToken}`).toString("base64")}`,
                },
            });
            // Obtener el buffer de la imagen
            const imageBuffer = await response.buffer();
            // Convertir la imagen a base64
            const imageBase64 = imageBuffer.toString("base64");
            // Crear el nombre del archivo en Firebase Storage
            const imageName = `${uuidv4()}.jpg`;
            const storageRef = ref(storage, `images/${imageName}`);
            const metadata = {
                contentType: "image/jpg",
            };
            // Funci√≥n para subir la imagen a Firebase Storage
            const uploadImage = () => {
                return new Promise((resolve, reject) => {
                    const uploadTask = uploadBytesResumable(storageRef, imageBuffer, metadata);
                    uploadTask.on("state_changed", (snapshot) => {
                        // Progreso de la subida (opcional)
                        console.log("Upload is in progress...");
                    }, (error) => {
                        reject(`Upload failed: ${error.message}`);
                    }, async () => {
                        // Subida completada, obtener la URL de descarga
                        const imageUrl = await getDownloadURL(uploadTask.snapshot.ref);
                        resolve(imageUrl);
                    });
                });
            };
            // Esperar a que la imagen se suba y obtener la URL
            try {
                const uploadedImageUrl = await uploadImage();
                // console.log('Uploaded Image URL:', uploadedImageUrl);
                // Guardar la imagen en Firebase Storage
                firebaseImageUrl = uploadedImageUrl;
                req.body.Body
                    ? (incomingMessage = req.body.Body)
                    : (incomingMessage = "");
                // Usar la imagen en base64 seg√∫n lo necesites
                const base64DataUrl = `data:image/jpeg;base64,${imageBase64}`;
                // console.log('Image in Base64:', base64DataUrl);
                // Puedes usar `base64DataUrl` para enviarla al modelo de OpenAI o guardarla en tu base de datos si es necesario.
                incomingImage = base64DataUrl; // Si quieres trabajar con la imagen en base64
            }
            catch (error) {
                console.error("Error uploading image:", error);
            }
        }
        else {
            incomingMessage = req.body.Body;
        }
        // const clientMessage = firebaseImageUrl ? firebaseImageUrl : incomingMessage;
        // Ejecutar la funci√≥n si el mensaje es del cliente
        await saveChatHistory(fromNumber, incomingMessage, true, firebaseImageUrl);
        // Validar si en el dashboard se encuentra activado el chat
        const chatOn = await getAvailableChatOn(fromNumber);
        console.log("üîç Estado del chat en dashboard:", chatOn ? "ACTIVADO" : "DESACTIVADO");
        // Si chat_on es false, quiero decir que en el dashboard est√° desactivado, as√≠ que ac√° se manda mensaje por agentOutput
        if (!chatOn) {
            // configuraci√≥n para crear hilos de conversaci√≥n en el agente y manejar memorias independientes.
            const config = {
                configurable: {
                    thread_id: fromNumber,
                    phone_number: fromNumber,
                },
            };
            console.log("=== INICIO DE PROCESAMIENTO MULTIAGENTE ===");
            console.log("üì± Cliente:", fromNumber);
            console.log("üí¨ Mensaje recibido:", incomingMessage);
            console.log("üîß Configuraci√≥n:", config);
            let agentOutput;
            if (incomingImage) {
                console.log("üñºÔ∏è Procesando mensaje con imagen...");
                const message = new HumanMessage({
                    content: [
                        {
                            type: "image_url",
                            image_url: { url: incomingImage },
                        },
                    ],
                });
                console.log("üì§ Enviando mensaje con imagen al supervisor...");
                agentOutput = await graph.invoke({
                    messages: [message],
                }, config);
            }
            else {
                console.log("üì§ Enviando mensaje de texto al supervisor...");
                agentOutput = await graph.invoke({
                    messages: [new HumanMessage({ content: incomingMessage })],
                }, config);
            }
            console.log("üîÑ Respuesta completa del sistema multiagente:");
            console.log("üìä N√∫mero total de mensajes:", agentOutput.messages.length);
            // Log detallado de todos los mensajes del flujo
            agentOutput.messages.forEach((msg, index) => {
                console.log(`üìù Mensaje ${index + 1}:`);
                console.log(`   - Tipo: ${msg.constructor.name}`);
                console.log(`   - Agente: ${msg.name || "No especificado"}`);
                // Manejar diferentes tipos de contenido
                let contentPreview = "Sin contenido";
                if (typeof msg.content === "string") {
                    contentPreview =
                        msg.content.substring(0, 100) +
                            (msg.content.length > 100 ? "..." : "");
                }
                else if (Array.isArray(msg.content)) {
                    contentPreview = "[Contenido complejo/multimedia]";
                }
                console.log(`   - Contenido: ${contentPreview}`);
            });
            const lastMessage = agentOutput.messages[agentOutput.messages.length - 1];
            // Determinar qu√© agente respondi√≥
            let respondingAgent = "Supervisor";
            if (lastMessage.name) {
                switch (lastMessage.name) {
                    case "SalesService":
                        respondingAgent = "Valentina R√≠os (Ventas)";
                        break;
                    case "TechnicalService":
                        respondingAgent = "Carlos Restrepo (Soporte T√©cnico)";
                        break;
                    case "CustomerService":
                        respondingAgent = "Mar√≠a Fernanda Ortiz (Atenci√≥n al Cliente)";
                        break;
                    default:
                        respondingAgent = lastMessage.name || "Supervisor";
                }
            }
            console.log("üéØ AGENTE QUE RESPONDE:", respondingAgent);
            console.log("üí≠ Respuesta final:", lastMessage.content);
            if (!lastMessage || typeof lastMessage.content !== "string") {
                console.error("Error: El mensaje de la IA es nulo o no es un string.");
                res
                    .status(500)
                    .send({ error: "La IA no gener√≥ una respuesta v√°lida." });
                return;
            }
            const responseMessage = lastMessage.content;
            console.log("üìã PROCESANDO RESPUESTA PARA ENV√çO:");
            console.log("üí¨ Respuesta IA:", responseMessage);
            console.log("üìè Longitud de respuesta:", responseMessage.length);
            // Ejecutar la funci√≥n si el mensaje es del agente
            await saveChatHistory(fromNumber, responseMessage, false, "");
            //consultar si esta disponible para audios
            const isAvailableForAudio = await getAvailableForAudio(fromNumber);
            console.log("üîä Cliente disponible para audio:", isAvailableForAudio);
            // console.log("isAvailableForAudio", isAvailableForAudio);
            // Si la respuesta es menor a 240 caracteres && no contiene n√∫meros, hacer TTS y enviar el audio
            if (responseMessage.length <= 400 && // Menor a 600 caracteres
                !/\d/.test(responseMessage) && // No contiene n√∫meros
                !/\b(?:[A-Z]{2,}|\b(?:[A-Z]\.){2,}[A-Z]?)\b/.test(responseMessage) && // No contiene siglas
                isAvailableForAudio // El cliente puede recibir audios
            ) {
                console.log("üéµ ENVIANDO RESPUESTA COMO AUDIO");
                console.log("‚úÖ Criterios para audio cumplidos:");
                console.log("   - Longitud ‚â§ 400 caracteres");
                console.log("   - No contiene n√∫meros");
                console.log("   - No contiene siglas");
                console.log("   - Cliente habilitado para audio");
                try {
                    const audioBuffer = await createAudioStreamFromText(responseMessage);
                    const audioName = `${uuidv4()}.wav`;
                    // Subir el archivo de audio a Firebase Storage
                    const storageRef = ref(storage, `audios/${audioName}`);
                    const metadata = {
                        contentType: "audio/mpeg",
                    };
                    const uploadTask = uploadBytesResumable(storageRef, audioBuffer, metadata);
                    // Esperar a que la subida complete y obtener la URL p√∫blica
                    uploadTask.on("state_changed", (snapshot) => {
                        // Progreso de la subida (opcional)
                        console.log("Upload is in progress...");
                    }, (error) => {
                        throw new Error(`Upload failed: ${error.message}`);
                    }, async () => {
                        // Subida completada
                        const audioUrl = await getDownloadURL(uploadTask.snapshot.ref);
                        // Env√≠a el archivo de audio a trav√©s de Twilio
                        await client.messages.create({
                            body: "Audio message",
                            from: to,
                            to: from,
                            mediaUrl: [audioUrl],
                        });
                        console.log("‚úÖ Audio message sent successfully");
                        console.log("üîó Audio URL:", audioUrl);
                        res.writeHead(200, { "Content-Type": "text/xml" });
                        res.end(twiml.toString());
                    });
                }
                catch (error) {
                    console.error("‚ùå Error sending audio message:", error);
                    console.log("üîÑ Fallback: Enviando como texto");
                    twiml.message(responseMessage);
                    res.writeHead(200, { "Content-Type": "text/xml" });
                    res.end(twiml.toString());
                }
            }
            else {
                console.log("üìù ENVIANDO RESPUESTA COMO TEXTO");
                console.log("‚ùå Criterios para audio NO cumplidos:");
                console.log("   - Longitud:", responseMessage.length, "caracteres");
                console.log("   - Contiene n√∫meros:", /\d/.test(responseMessage));
                console.log("   - Contiene siglas:", /\b(?:[A-Z]{2,}|\b(?:[A-Z]\.){2,}[A-Z]?)\b/.test(responseMessage));
                console.log("   - Cliente habilitado para audio:", isAvailableForAudio);
                // Responder con el texto si es mayor de 350 caracteres
                if (responseMessage.length > 1000) {
                    console.log("üìÑ Mensaje muy largo, dividiendo en partes...");
                    const messageParts = responseMessage.split("\n\n");
                    console.log("üî¢ N√∫mero de partes:", messageParts.length);
                    // eslint-disable-next-line prefer-const
                    for (let part of messageParts) {
                        if (part !== "") {
                            await client.messages.create({
                                body: part,
                                from: to,
                                to: from,
                            });
                            console.log("üì§ Enviada parte:", part.substring(0, 50) + "...");
                            console.log("-------------------");
                        }
                    }
                    console.log("‚úÖ Todas las partes enviadas exitosamente");
                }
                else {
                    try {
                        const message = await client.messages.create({
                            body: responseMessage,
                            from: to,
                            to: from,
                        });
                        console.log("‚úÖ Message sent successfully:", message.sid);
                    }
                    catch (error) {
                        console.error("‚ùå Error sending message:", error);
                    }
                }
            }
            console.log("=== FIN DE PROCESAMIENTO MULTIAGENTE ===");
            console.log("üì± Cliente:", fromNumber);
            console.log("üéØ Agente final:", respondingAgent);
            console.log("üïê Timestamp:", new Date().toISOString());
            console.log("===============================================");
        }
        else {
            console.log("üë§ MODO HUMANO ACTIVADO");
            console.log("üì± Cliente:", fromNumber);
            console.log("üí¨ Mensaje guardado para atenci√≥n humana:", incomingMessage);
            console.log("‚è≥ Esperando respuesta del agente humano...");
        }
    }
    catch (error) {
        console.error("‚ùå Error in chat route:", error);
        res.status(500).send({
            error: error instanceof Error ? error.message : "An unknown error occurred",
        });
    }
});
router.post("/induequipos/chat-dashboard", async (req, res) => {
    try {
        const twiml = new MessagingResponse();
        const { clientNumber, newMessage } = req.body;
        const isAudioMessage = await newMessage.includes("https://firebasestorage.googleapis.com/v0/b/ultim-admin-dashboard.appspot.com/o/audios");
        const isFileMessage = await newMessage.includes("https://firebasestorage.googleapis.com/v0/b/ultim-admin-dashboard.appspot.com/o/documents");
        if (isAudioMessage) {
            console.log("Audio message detected");
            // Descargar el archivo desde Firebase
            const audioUrl = newMessage;
            const response = await fetch(audioUrl);
            const audioBuffer = await response.buffer();
            const tempDir = path.join(__dirname, "../temp"); // Subir un nivel desde routes
            const tempInputPath = path.join(tempDir, "tempInput.webm");
            const tempOutputPath = path.join(tempDir, "tempOutput.mp3");
            // Guardar el archivo temporal
            fs.writeFileSync(tempInputPath, new Uint8Array(audioBuffer));
            // Convertir a formato OGG usando ffmpeg
            await new Promise((resolve, reject) => {
                ffmpeg(tempInputPath)
                    .output(tempOutputPath)
                    .inputOptions("-f", "webm")
                    .audioCodec("libmp3lame")
                    .on("start", (commandLine) => {
                    console.log("Comando FFmpeg:", commandLine);
                })
                    .on("end", resolve)
                    .on("error", reject)
                    .run();
            });
            // Subir el audio convertido a Firebase Storage a la capeta audios
            const audioName = `audio_${uuidv4()}.mp3`;
            const storageRef = ref(storage, `ogg/${audioName}`);
            const metadata = {
                contentType: "audio/mpeg",
            };
            const uploadTask = uploadBytesResumable(storageRef, fs.readFileSync(tempOutputPath), metadata);
            console.log("Nombre creado", audioName);
            // Esperar a que la subida complete y obtener la URL p√∫blica
            uploadTask.on("state_changed", (snapshot) => {
                // Progreso de la subida (opcional)
                console.log("Upload is in progress...");
            }, (error) => {
                throw new Error(`Upload failed: ${error.message}`);
            }, async () => {
                // Subida completada
                const audioUrl = await getDownloadURL(uploadTask.snapshot.ref);
                console.log("Audio URL:", audioUrl);
                // Env√≠a el archivo de audio a trav√©s de Twilio
                await client.messages.create({
                    body: "Audio message",
                    to: `whatsapp:${clientNumber}`,
                    // from: `whatsapp:+5745012080`,
                    from: `whatsapp:+14155238886`,
                    mediaUrl: [audioUrl],
                });
                // Limpiar archivos temporales
                fs.unlinkSync(tempInputPath);
                fs.unlinkSync(tempOutputPath);
                console.log("Audio message sent successfully", audioUrl);
                res.writeHead(200, { "Content-Type": "text/xml" });
                res.end(twiml.toString());
            });
        }
        else if (isFileMessage) {
            console.log("File message detected");
            const message = await client.messages.create({
                // body: 'Mensaje con archivo',
                to: `whatsapp:${clientNumber}`,
                // from: `whatsapp:+5745012080`,
                from: `whatsapp:+14155238886`,
                mediaUrl: [newMessage],
            });
            console.log("File message sent successfully:", message.sid);
            res.writeHead(200, { "Content-Type": "text/xml" });
            res.end(twiml.toString());
        }
        else {
            // Enviar mensaje a trav√©s de Twilio
            const message = await client.messages.create({
                from: "whatsapp:+14155238886", // N√∫mero de Twilio de pruebas
                // from: `whatsapp:+5745012080`, // N√∫mero de Coltefinanciera
                to: `whatsapp:${clientNumber}`,
                body: newMessage,
            });
            // Enviar respuesta al frontend
            res.status(200).send({
                success: true,
                message: "Mensaje enviado exitosamente",
                sid: message.sid,
            });
        }
    }
    catch (error) {
        console.error("Error in chat route:", error);
        res.status(500).send({
            error: error instanceof Error ? error.message : "An unknown error occurred",
        });
    }
});
// Ruta para enviar una plantilla de WhatsApp
router.post("/induequipos/send-template", async (req, res) => {
    const { to, templateId, name, paymentDate, amount, user } = req.body;
    try {
        const message = await client.messages.create({
            // from: 'whatsapp:+5745012080',
            from: "whatsapp:+14155238886",
            to: `whatsapp:${to}`,
            contentSid: templateId,
            messagingServiceSid: "MGe5ebd75ff86ad20dbe6c0c1d09bfc081",
            contentVariables: JSON.stringify({ 1: name, 2: paymentDate, 3: amount }),
        });
        console.log("body", message.body);
        await new Promise((resolve) => setTimeout(resolve, 2000));
        // Traer el mensaje de la plantilla desde el endpoint /message/:sid con axios
        const response = await axios.get(`https://ultim.online/fenix/message/${message.sid}`);
        console.log("response", response.data.message.body);
        // Guardar el mensaje en la base de datos (simulado)
        await saveTemplateChatHistory(to, response.data.message.body, false, "", user);
        res.status(200).json({
            success: true,
            message: response.data.message.body,
            sid: message.sid,
        });
    }
    catch (error) {
        res.status(500).json({
            success: false,
            message: "Error al enviar la plantilla",
            error: error instanceof Error ? error.message : "An unknown error occurred",
        });
    }
});
// Ruta para obtener detalles de un mensaje espec√≠fico por SID
router.get("/induequipos/message/:sid", async (req, res) => {
    const { sid } = req.params;
    try {
        const message = await client.messages(sid).fetch();
        res.status(200).json({ success: true, message });
    }
    catch (error) {
        res.status(500).json({
            success: false,
            message: "Error al obtener el mensaje",
            error: error instanceof Error ? error.message : "An unknown error occurred",
        });
    }
});
// Endpoint de pruebas para la interfaz React
// @ts-ignore
router.post("/api/test-chat", async (req, res) => {
    try {
        const { message } = req.body;
        // Validar que el mensaje est√© presente
        if (!message || typeof message !== "string") {
            return res.status(400).json({
                success: false,
                error: 'El campo "message" es requerido y debe ser un string',
            });
        }
        // Configuraci√≥n para el grafo (usando un thread_id √∫nico para pruebas)
        const config = {
            configurable: {
                thread_id: `test-1`, // Thread √∫nico para cada prueba
                phone_number: "test-user",
            },
        };
        console.log("=== INICIO DE PRUEBA MULTIAGENTE ===");
        console.log("üß™ Modo: Prueba desde interfaz React");
        console.log("üí¨ Mensaje de prueba:", message);
        console.log("üîß Configuraci√≥n:", config);
        // Enviar mensaje al grafo de LangGraph
        console.log("üì§ Enviando mensaje al supervisor (modo prueba)...");
        const agentOutput = await graph.invoke({
            messages: [new HumanMessage({ content: message })],
        }, config);
        console.log("üîÑ Respuesta completa del sistema multiagente (prueba):");
        console.log("üìä N√∫mero total de mensajes:", agentOutput.messages.length);
        // Log detallado de todos los mensajes del flujo
        agentOutput.messages.forEach((msg, index) => {
            console.log(`üìù Mensaje ${index + 1}:`);
            console.log(`   - Tipo: ${msg.constructor.name}`);
            console.log(`   - Agente: ${msg.name || "No especificado"}`);
            // Manejar diferentes tipos de contenido
            let contentPreview = "Sin contenido";
            if (typeof msg.content === "string") {
                contentPreview =
                    msg.content.substring(0, 100) +
                        (msg.content.length > 100 ? "..." : "");
            }
            else if (Array.isArray(msg.content)) {
                contentPreview = "[Contenido complejo/multimedia]";
            }
            console.log(`   - Contenido: ${contentPreview}`);
        });
        // Obtener la respuesta del √∫ltimo mensaje
        const lastMessage = agentOutput.messages[agentOutput.messages.length - 1];
        if (!lastMessage || typeof lastMessage.content !== "string") {
            console.log("‚ùå Error: La IA no gener√≥ una respuesta v√°lida");
            return res.status(500).json({
                success: false,
                error: "La IA no gener√≥ una respuesta v√°lida",
            });
        }
        // Determinar qu√© agente respondi√≥ bas√°ndose en el nombre del mensaje
        let agentName = "Supervisor";
        if (lastMessage.name) {
            switch (lastMessage.name) {
                case "SalesService":
                    agentName = "Valentina R√≠os (Ventas)";
                    break;
                case "TechnicalService":
                    agentName = "Carlos Restrepo (Soporte T√©cnico)";
                    break;
                case "CustomerService":
                    agentName = "Mar√≠a Fernanda Ortiz (Atenci√≥n al Cliente)";
                    break;
                default:
                    agentName = "Supervisor";
            }
        }
        console.log("üéØ AGENTE QUE RESPONDE:", agentName);
        console.log("üí≠ Respuesta final:", lastMessage.content);
        console.log("üïê Timestamp:", new Date().toISOString());
        console.log("=== FIN DE PRUEBA MULTIAGENTE ===");
        // Responder con formato JSON
        res.status(200).json({
            success: true,
            response: lastMessage.content,
            agent: agentName,
            timestamp: new Date().toISOString(),
        });
    }
    catch (error) {
        console.error("Error en endpoint de pruebas:", error);
        res.status(500).json({
            success: false,
            error: error instanceof Error ? error.message : "Error desconocido",
        });
    }
});
export default router;
export { exportedFromNumber };
